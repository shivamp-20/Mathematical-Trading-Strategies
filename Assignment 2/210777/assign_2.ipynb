{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d7130d7d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "NASDAQ data:\n",
      "                   Open         High          Low        Close    Adj Close  \\\n",
      "Date                                                                          \n",
      "2010-01-04  2294.409912  2311.149902  2294.409912  2308.419922  2308.419922   \n",
      "2010-01-05  2307.270020  2313.729980  2295.620117  2308.709961  2308.709961   \n",
      "2010-01-06  2307.709961  2314.070068  2295.679932  2301.090088  2301.090088   \n",
      "2010-01-07  2298.090088  2301.300049  2285.219971  2300.050049  2300.050049   \n",
      "2010-01-08  2292.239990  2317.600098  2290.610107  2317.169922  2317.169922   \n",
      "\n",
      "                Volume  \n",
      "Date                    \n",
      "2010-01-04  1931380000  \n",
      "2010-01-05  2367860000  \n",
      "2010-01-06  2253340000  \n",
      "2010-01-07  2270050000  \n",
      "2010-01-08  2145390000  \n",
      "\n",
      "NSE data:\n",
      "                   Open         High          Low        Close    Adj Close  \\\n",
      "Date                                                                          \n",
      "2010-01-04  5200.899902  5238.450195  5167.100098  5232.200195  5232.200195   \n",
      "2010-01-05  5277.149902  5288.350098  5242.399902  5277.899902  5277.899902   \n",
      "2010-01-06  5278.149902  5310.850098  5260.049805  5281.799805  5281.799805   \n",
      "2010-01-07  5281.799805  5302.549805  5244.750000  5263.100098  5263.100098   \n",
      "2010-01-08  5264.250000  5276.750000  5234.700195  5244.750000  5244.750000   \n",
      "\n",
      "            Volume  \n",
      "Date                \n",
      "2010-01-04       0  \n",
      "2010-01-05       0  \n",
      "2010-01-06       0  \n",
      "2010-01-07       0  \n",
      "2010-01-08       0  \n"
     ]
    }
   ],
   "source": [
    "import yfinance as yf\n",
    "import pandas as pd\n",
    "\n",
    "# Define the ticker symbols for NASDAQ and NSE indices\n",
    "nasdaq_symbol = \"^IXIC\"  # NASDAQ ticker symbol\n",
    "nse_symbol = \"^NSEI\"  # NSE ticker symbol\n",
    "\n",
    "# Set the start and end dates for the historical data\n",
    "start_date = \"2010-01-01\"  # Replace with your desired start date\n",
    "end_date = \"2023-05-01\"  # Replace with your desired end date\n",
    "\n",
    "# Use yf.download() to retrieve the historical data\n",
    "nasdaq_data = yf.download(nasdaq_symbol, start=start_date, end=end_date)\n",
    "nse_data = yf.download(nse_symbol, start=start_date, end=end_date)\n",
    "\n",
    "# Convert the data to pandas DataFrames\n",
    "nasdaq_df = pd.DataFrame(nasdaq_data)\n",
    "nse_df = pd.DataFrame(nse_data)\n",
    "\n",
    "# Display the first few rows of each DataFrame\n",
    "print(\"NASDAQ data:\")\n",
    "print(nasdaq_df.head())\n",
    "print(\"\\nNSE data:\")\n",
    "print(nse_df.head())\n",
    "\n",
    "# Save the data as CSV files\n",
    "nasdaq_df.to_csv(\"nasdaq_data.csv\", index=False)\n",
    "nse_df.to_csv(\"nse_data.csv\", index=False)\n",
    "import pandas as pd\n",
    "\n",
    "nasdaq_df = pd.read_csv(\"nasdaq_data.csv\")\n",
    "nse_df = pd.read_csv(\"nse_data.csv\")\n",
    "nasdaq_close = nasdaq_df[\"Close\"]\n",
    "nse_close = nse_df[\"Close\"]\n",
    "correlation_coefficient = nasdaq_close.corr(nse_close)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f37e3a28",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Correlation coefficient: 0.9607951810049128\n"
     ]
    }
   ],
   "source": [
    "print(\"Correlation coefficient:\", correlation_coefficient)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35bf6a92",
   "metadata": {},
   "source": [
    "The correlation coefficient of 0.9608 is very close to 1, which indicates a high degree of correlation. This means that the movements of the NASDAQ and NSE indices are highly synchronized, and they tend to move in the same direction with a similar magnitude.\n",
    "\n",
    "Overall, the analysis of the correlation coefficient suggests a strong positive relationship between the NASDAQ and NSE indices, indicating that they are closely related and move in a similar pattern.\n",
    "\n",
    "however ,correlation does not imply causation. While there is a strong correlation between the two indices, it does not necessarily mean that one index causes the other to move. It is important to consider other factors and conduct further analysis to understand the underlying dynamics and potential causality.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6da3d38e",
   "metadata": {},
   "outputs": [],
   "source": [
    "nasdaq_df['NASDAQ_PctChange'] = nasdaq_df['Close'].pct_change()\n",
    "nse_df['NSE_PctChange'] = nse_df['Close'].pct_change()\n",
    "nse_df['Lagged_NASDAQ_PctChange'] = nasdaq_df['NASDAQ_PctChange'].shift(1)\n",
    "nse_df['LeadLag_Difference'] = nse_df['Lagged_NASDAQ_PctChange'] - nse_df['NSE_PctChange']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "3b1e7a47",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['Open', 'High', 'Low', 'Close', 'Adj Close', 'Volume', 'NSE_PctChange',\n",
      "       'Lagged_NASDAQ_PctChange', 'LeadLag_Difference'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Print the column names\n",
    "print(nse_df.columns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a7e41ad6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Open                       float64\n",
      "High                       float64\n",
      "Low                        float64\n",
      "Close                      float64\n",
      "Adj Close                  float64\n",
      "Volume                       int64\n",
      "NSE_PctChange              float64\n",
      "Lagged_NASDAQ_PctChange    float64\n",
      "LeadLag_Difference         float64\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Print the data types of all columns\n",
    "print(nse_df.dtypes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b6e8b63b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  1 of 1 completed\n",
      "                  Open        High         Low       Close   Adj Close  \\\n",
      "Date                                                                     \n",
      "2022-01-03  177.830002  182.880005  177.710007  182.009995  180.434296   \n",
      "2022-01-04  182.630005  182.940002  179.119995  179.699997  178.144287   \n",
      "2022-01-05  179.610001  180.169998  174.639999  174.919998  173.405670   \n",
      "2022-01-06  172.699997  175.300003  171.639999  172.000000  170.510941   \n",
      "2022-01-07  172.889999  174.139999  171.029999  172.169998  170.679489   \n",
      "\n",
      "               Volume  \n",
      "Date                   \n",
      "2022-01-03  104487900  \n",
      "2022-01-04   99310400  \n",
      "2022-01-05   94537600  \n",
      "2022-01-06   96904000  \n",
      "2022-01-07   86709100  \n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'historical_prices.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m----------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                    Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[21], line 20\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[38;5;28mprint\u001b[39m(df\u001b[38;5;241m.\u001b[39mhead())\n\u001b[0;32m     18\u001b[0m \u001b[38;5;66;03m# Load the historical price data into a Pandas DataFrame\u001b[39;00m\n\u001b[0;32m     19\u001b[0m \u001b[38;5;66;03m# Replace 'df' with the actual DataFrame containing the price data\u001b[39;00m\n\u001b[1;32m---> 20\u001b[0m df \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mhistorical_prices.csv\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     22\u001b[0m period \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m20\u001b[39m  \u001b[38;5;66;03m# Define the period for the Keltner Channel\u001b[39;00m\n\u001b[0;32m     23\u001b[0m atr_period \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m10\u001b[39m  \u001b[38;5;66;03m# Define the period for calculating Average True Range (ATR)\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\pandas\\io\\parsers\\readers.py:912\u001b[0m, in \u001b[0;36mread_csv\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[0;32m    899\u001b[0m kwds_defaults \u001b[38;5;241m=\u001b[39m _refine_defaults_read(\n\u001b[0;32m    900\u001b[0m     dialect,\n\u001b[0;32m    901\u001b[0m     delimiter,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    908\u001b[0m     dtype_backend\u001b[38;5;241m=\u001b[39mdtype_backend,\n\u001b[0;32m    909\u001b[0m )\n\u001b[0;32m    910\u001b[0m kwds\u001b[38;5;241m.\u001b[39mupdate(kwds_defaults)\n\u001b[1;32m--> 912\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\pandas\\io\\parsers\\readers.py:577\u001b[0m, in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    574\u001b[0m _validate_names(kwds\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnames\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[0;32m    576\u001b[0m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[1;32m--> 577\u001b[0m parser \u001b[38;5;241m=\u001b[39m TextFileReader(filepath_or_buffer, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[0;32m    579\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[0;32m    580\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\pandas\\io\\parsers\\readers.py:1407\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[1;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[0;32m   1404\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m kwds[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m   1406\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles: IOHandles \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m-> 1407\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_make_engine\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mengine\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\pandas\\io\\parsers\\readers.py:1661\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[1;34m(self, f, engine)\u001b[0m\n\u001b[0;32m   1659\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m mode:\n\u001b[0;32m   1660\u001b[0m         mode \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m-> 1661\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;241m=\u001b[39m \u001b[43mget_handle\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1662\u001b[0m \u001b[43m    \u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1663\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1664\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1665\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcompression\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1666\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmemory_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmemory_map\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1667\u001b[0m \u001b[43m    \u001b[49m\u001b[43mis_text\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_text\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1668\u001b[0m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding_errors\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstrict\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1669\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstorage_options\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1670\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1671\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1672\u001b[0m f \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles\u001b[38;5;241m.\u001b[39mhandle\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\pandas\\io\\common.py:859\u001b[0m, in \u001b[0;36mget_handle\u001b[1;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[0;32m    854\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(handle, \u001b[38;5;28mstr\u001b[39m):\n\u001b[0;32m    855\u001b[0m     \u001b[38;5;66;03m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[0;32m    856\u001b[0m     \u001b[38;5;66;03m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[0;32m    857\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mencoding \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mmode:\n\u001b[0;32m    858\u001b[0m         \u001b[38;5;66;03m# Encoding\u001b[39;00m\n\u001b[1;32m--> 859\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[0;32m    860\u001b[0m \u001b[43m            \u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    861\u001b[0m \u001b[43m            \u001b[49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    862\u001b[0m \u001b[43m            \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    863\u001b[0m \u001b[43m            \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    864\u001b[0m \u001b[43m            \u001b[49m\u001b[43mnewline\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    865\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    866\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    867\u001b[0m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[0;32m    868\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(handle, ioargs\u001b[38;5;241m.\u001b[39mmode)\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'historical_prices.csv'"
     ]
    }
   ],
   "source": [
    "\n",
    "import talib\n",
    "\n",
    "\n",
    "# Define the symbol or ticker for the desired stock\n",
    "symbol = 'AAPL'\n",
    "\n",
    "# Define the start and end dates for the historical data\n",
    "start_date = '2010-01-01'\n",
    "end_date = '2023-05-01'\n",
    "\n",
    "# Fetch the historical price data using yfinance\n",
    "df = yf.download(symbol, start=start_date, end=end_date)\n",
    "\n",
    "# Print the first few rows of the DataFrame to verify the data\n",
    "print(df.head())\n",
    "\n",
    "\n",
    "# Load the historical price data into a Pandas DataFrame\n",
    "# Replace 'df' with the actual DataFrame containing the price data\n",
    "df = pd.read_csv('historical_prices.csv')\n",
    "\n",
    "period = 20  # Define the period for the Keltner Channel\n",
    "atr_period = 10  # Define the period for calculating Average True Range (ATR)\n",
    "bb_period = 20  # Define the period for the Bollinger Bands\n",
    "std_dev = 2  # Define the number of standard deviations\n",
    "macd_fast_period = 12  # Define the period for the fast line of MACD\n",
    "macd_slow_period = 26  # Define the period for the slow line of MACD\n",
    "macd_signal_period = 9  # Define the period for the signal line of MACD\n",
    "\n",
    "# Calculate the necessary components for the Keltner Channel\n",
    "high = df['High']\n",
    "low = df['Low']\n",
    "close = df['Close']\n",
    "atr = talib.ATR(high, low, close, timeperiod=atr_period)  # Calculate ATR\n",
    "keltner_upper = talib.SMA(close, timeperiod=period) + atr * 1.5\n",
    "keltner_middle = talib.SMA(close, timeperiod=period)\n",
    "keltner_lower = talib.SMA(close, timeperiod=period) - atr * 1.5\n",
    "\n",
    "# Calculate the Bollinger Bands\n",
    "bb_upper, bb_middle, bb_lower = talib.BBANDS(close, timeperiod=bb_period, nbdevup=std_dev, nbdevdn=std_dev)\n",
    "\n",
    "# Calculate the MACD\n",
    "macd, macd_signal, macd_hist = talib.MACD(close, fastperiod=macd_fast_period, slowperiod=macd_slow_period,\n",
    "                                         signalperiod=macd_signal_period)\n",
    "\n",
    "# Add the Keltner Channel, Bollinger Bands, and MACD values to the DataFrame\n",
    "df['Keltner_Upper'] = keltner_upper\n",
    "df['Keltner_Middle'] = keltner_middle\n",
    "df['Keltner_Lower'] = keltner_lower\n",
    "df['BB_Upper'] = bb_upper\n",
    "df['BB_Middle'] = bb_middle\n",
    "df['BB_Lower'] = bb_lower\n",
    "df['MACD'] = macd\n",
    "df['MACD_Signal'] = macd_signal\n",
    "df['MACD_Histogram'] = macd_hist\n",
    "\n",
    "# Analyze the indicators and their values for further analysis or trading strategy development\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "54063d0d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hp\\Downloads\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "print(os.getcwd())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a16cc1cf",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  1 of 1 completed\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'performance_metric' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m----------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[22], line 37\u001b[0m\n\u001b[0;32m     35\u001b[0m \u001b[38;5;66;03m# Perform parameter optimization\u001b[39;00m\n\u001b[0;32m     36\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m period \u001b[38;5;129;01min\u001b[39;00m periods:\n\u001b[1;32m---> 37\u001b[0m     performance \u001b[38;5;241m=\u001b[39m \u001b[43moptimize_parameters\u001b[49m\u001b[43m(\u001b[49m\u001b[43mperiod\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     38\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m performance \u001b[38;5;241m>\u001b[39m best_performance:\n\u001b[0;32m     39\u001b[0m         best_performance \u001b[38;5;241m=\u001b[39m performance\n",
      "Cell \u001b[1;32mIn[22], line 30\u001b[0m, in \u001b[0;36moptimize_parameters\u001b[1;34m(period)\u001b[0m\n\u001b[0;32m     24\u001b[0m keltner_lower \u001b[38;5;241m=\u001b[39m talib\u001b[38;5;241m.\u001b[39mSMA(close, timeperiod\u001b[38;5;241m=\u001b[39mperiod) \u001b[38;5;241m-\u001b[39m atr \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m1.5\u001b[39m\n\u001b[0;32m     26\u001b[0m \u001b[38;5;66;03m# Define your strategy and evaluate its performance\u001b[39;00m\n\u001b[0;32m     27\u001b[0m \u001b[38;5;66;03m# Use the metrics coded in your last assignment to calculate the performance metric\u001b[39;00m\n\u001b[0;32m     28\u001b[0m \n\u001b[0;32m     29\u001b[0m \u001b[38;5;66;03m# Return the performance metric\u001b[39;00m\n\u001b[1;32m---> 30\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mperformance_metric\u001b[49m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'performance_metric' is not defined"
     ]
    }
   ],
   "source": [
    "import yfinance as yf\n",
    "import talib\n",
    "\n",
    "# Define the symbol or ticker for the index\n",
    "symbol = '^GSPC'\n",
    "\n",
    "# Define the start and end dates for the historical data\n",
    "start_date = '2018-01-01'\n",
    "end_date = '2022-12-31'\n",
    "\n",
    "# Fetch the historical price data using yfinance\n",
    "data = yf.download(symbol, start=start_date, end=end_date)\n",
    "\n",
    "# Define the parameter space for the period of the Keltner Channel\n",
    "periods = [10, 20, 30, 40, 50]\n",
    "\n",
    "# Define the optimization function\n",
    "def optimize_parameters(period):\n",
    "    # Calculate the Keltner Channel with the given period\n",
    "    close = data['Close']\n",
    "    atr = talib.ATR(data['High'], data['Low'], close, timeperiod=10)\n",
    "    keltner_upper = talib.SMA(close, timeperiod=period) + atr * 1.5\n",
    "    keltner_middle = talib.SMA(close, timeperiod=period)\n",
    "    keltner_lower = talib.SMA(close, timeperiod=period) - atr * 1.5\n",
    "\n",
    "    # Define your strategy and evaluate its performance\n",
    "    # Use the metrics coded in your last assignment to calculate the performance metric\n",
    "\n",
    "    # Return the performance metric\n",
    "    return performance_metric\n",
    "\n",
    "best_performance = float('-inf')\n",
    "best_period = None\n",
    "\n",
    "# Perform parameter optimization\n",
    "for period in periods:\n",
    "    performance = optimize_parameters(period)\n",
    "    if performance > best_performance:\n",
    "        best_performance = performance\n",
    "        best_period = period\n",
    "\n",
    "# Document the optimized parameters\n",
    "print(\"Optimized parameters:\")\n",
    "print(\"Period for Keltner Channel:\", best_period)\n",
    "print(\"Performance metric:\", best_performance)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7e1c4e5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
